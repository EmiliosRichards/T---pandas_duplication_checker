{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final cleaned data saved to cleaned_data_20250526_121351.xlsx\n",
      "Original A rows: 6615\n",
      "Removed due to URL match: 2465\n",
      "Final cleaned A rows: 4150\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Load both Excel files, treating all columns as strings (important for preserving data integrity)\n",
    "df_compared_to = pd.read_excel(r\"data\\Anna_sent\\Kunden wie Medwing 02.06.25.xlsx\", dtype=str)\n",
    "df_getting_changed = pd.read_excel(r\"single_output\\Adressen Blister-schoko-Kanabis_27.05.25_deduped.xlsx\", dtype=str)\n",
    "\n",
    "# Optional: Drop internal duplicates within each file by URL\n",
    "df_getting_changed = df_getting_changed.drop_duplicates(subset=[\"URL\"])\n",
    "df_compared_to = df_compared_to.drop_duplicates(subset=[\"URL\"])\n",
    "\n",
    "# Ensure comparison_logs folder exists\n",
    "os.makedirs(\"comparison_logs\", exist_ok=True)\n",
    "\n",
    "# Ensure comparison_logs folder exists\n",
    "os.makedirs(\"comparison_output\", exist_ok=True)\n",
    "\n",
    "# Step 1: Identify rows in A that have matching URLs in B\n",
    "matching_urls = df_getting_changed[df_getting_changed[\"URL\"].isin(df_compared_to[\"URL\"])]\n",
    "\n",
    "# Step 2: Remove those rows from A\n",
    "df_result = df_getting_changed[~df_getting_changed[\"URL\"].isin(df_compared_to[\"URL\"])]\n",
    "\n",
    "# Step 3: Save outputs\n",
    "matching_urls.to_excel(f\"comparison_logs/matching_urls_{timestamp}.xlsx\", index=False)\n",
    "\n",
    "# Save cleaned result with formatting\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "with pd.ExcelWriter(f\"comparison_output\\cleaned_data_{timestamp}.xlsx\", engine=\"openpyxl\") as writer:\n",
    "    df_result.to_excel(writer, index=False, sheet_name=\"Sheet1\")\n",
    "\n",
    "    worksheet = writer.sheets[\"Sheet1\"]\n",
    "\n",
    "    # 1. Format 'Number' column as text\n",
    "    if \"Number\" in df_result.columns:\n",
    "        number_col_idx = df_result.columns.get_loc(\"Number\")\n",
    "        number_col_letter = get_column_letter(number_col_idx + 1)  # openpyxl columns are 1-based\n",
    "\n",
    "        for row in range(2, len(df_result) + 2):  # Skip header, Excel rows are 1-based\n",
    "            cell = worksheet[f\"{number_col_letter}{row}\"]\n",
    "            cell.number_format = \"@\"\n",
    "\n",
    "    # 2. Auto-adjust column widths\n",
    "    for col_idx, column_cells in enumerate(worksheet.columns, 1):\n",
    "        max_length = max(\n",
    "            len(str(cell.value)) if cell.value is not None else 0\n",
    "            for cell in column_cells\n",
    "        )\n",
    "        adjusted_width = max_length + 2\n",
    "        col_letter = get_column_letter(col_idx)\n",
    "        worksheet.column_dimensions[col_letter].width = adjusted_width\n",
    "\n",
    "print(f\"✅ Final cleaned data saved to cleaned_data_{timestamp}.xlsx\")\n",
    "print(f\"Original A rows: {len(df_getting_changed)}\")\n",
    "print(f\"Removed due to URL match: {len(matching_urls)}\")\n",
    "print(f\"Final cleaned A rows: {len(df_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961b908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
